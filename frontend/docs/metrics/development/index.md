# Development Metrics Explained

This section explains the development activity metrics tracked by LFX Insights. These metrics help assess <b>how actively and efficiently an open source project is being developed and maintained</b>.

:::info Please note
The Development metrics include actions performed by bots. We include bot activities because they often represent important automated processes in modern development workflows (such as automated testing, dependency updates, and CI/CD processes). Excluding these would result in incomplete data for development activity analysis. Bot actions are excluded from all other metric categories.
:::

## Issues Resolution

**What it is:** The number of issues opened, closed, and the average time it takes to resolve them.

**Why it matters:** Helps gauge how responsive and attentive maintainers are to user-reported problems and feature requests.

## Pull Requests

**What it is:** Metrics related to pull requests (PRs), including how many are opened, closed, merged, and rejected.

**Why it matters:** Shows the pace of development and community contribution. A healthy volume of PRs indicates active collaboration and iteration.

## Active Days

**What it is:** The number of days with at least one recorded development activity (e.g., commit, PR, issue).

**Why it matters:** Reveals how consistently a project is being maintained. More active days suggest ongoing and sustained development.

## Contributions Outside Work Hours

**What it is:** The percentage of contributions made outside standard weekday working hours.

**Why it matters:** Gives insight into contributor behaviorâ€”whether it's mostly hobbyist-driven or supported during work hours by employers. High off-hours activity may suggest volunteer-driven maintenance.

## Merge Lead Time

**What it is:** The average time between a pull request being opened and when it's merged.

**Why it matters:** Indicates how quickly contributions are reviewed and integrated. Shorter times often mean more responsive maintainers and faster iteration.

## Review Time by Pull Request Size

**What it is:** The average review time categorized by the size (lines of code) of the pull request.

**Why it matters:** Helps evaluate how review complexity affects project responsiveness. Long review times on small PRs might signal process inefficiencies.

## Average Time to Merge

**What it is:** The overall average duration between PR creation and merge.

**Why it matters:** Measures the efficiency of the contribution process. Fast merge times can improve contributor experience and project agility.

## Wait Time for First Review

**What it is:** The average time it takes for a pull request to receive its first review after being opened.

**Why it matters:** Early engagement is critical to keeping contributors motivated. Faster first reviews encourage participation and reduce contributor churn.

## Code Review Engagement

**What it is:** Metrics that show how many reviewers are involved per PR and the overall level of code review activity.

**Why it matters:** Strong review engagement improves code quality, spreads knowledge across maintainers, and indicates healthy project governance.
